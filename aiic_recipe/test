sudo python3 -m pip uninstall bytedray -y && sudo python3 -m pip install --force-reinstall "ray[data,train,tune,serve]"
sudo python3 -m pip uninstall grpcio -y && sudo python3 -m pip install grpcio==1.62.1
sudo python3 -m pip uninstall byted-wandb -y && sudo python3 -m pip install wandb==0.23.1
sudo python3 -m pip uninstall verl
sudo python3 -m pip install protobuf==4.25.3
sudo python3 -m pip install numba==0.63.1
sudo python3 -m pip install sandbox_fusion
sudo python3 -m pip install logfire
sudo python3 -m pip install pydantic-core==2.41.5

# Install firejail and sandbox dependencies
sudo DEBIAN_FRONTEND=noninteractive apt-get -y -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" install firejail
sudo python3 -m pip install "fastapi[all]" uvicorn

export WANDB_API_KEY=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
# export LOGFIRE_KEY=pylf_v1_us_WDr56TvhGPcGq7Sllx7mvHklQy4Wg2rQPYC93cYWRGFb
export NGPUS_PER_NODE=8
export NNODES=$ARNOLD_WORKER_NUM
export NODE_RANK=$ARNOLD_ID
export MASTER_ADDR=$ARNOLD_WORKER_0_HOST
export MASTER_PORT=$(echo $ARNOLD_WORKER_0_PORT | cut -d',' -f1)

# bash aiic_recipe/start_sandbox.sh

bash ace/start_ray.sh aiic_recipe/train.sh \
    --entrypoint aiic_recipe.main \
    --config_name trainer.yaml \
    --project_name code_rl \
    --exp_name 0205-code-single-turn-qwen3-4b-instruct-2507-mis-oversample-16k-local-sandbox \
    --model_path /mnt/hdfs/tiktok_aiic/user/codeai/hf_models/Qwen3-4B-Instruct-2507 \
    --data_path /mnt/hdfs/tiktok_aiic/user/longtao.zheng/rl_datasets \
    --train_data leetcode/train.jsonl \
    --test_data leetcode/test.jsonl \
    --data_custom_cls_path aiic_recipe/dataset/code.py \
    --data_custom_cls_name SingleTurnCodeRLDataset \
    --reward_manager rate_limited \
    --custom_reward_path aiic_recipe/reward_score/code.py \
    --custom_reward_name compute_score \
    --ckpt_path /mnt/hdfs/tiktok_aiic/user/longtao.zheng/code_rl_checkpoints \
    --max_prompt_length 4096 \
    --max_response_length 12288 \
    --train_sp 2 \
    --actor_max_token_len_per_gpu 8192 \
    --log_prob_max_token_len_per_gpu 16384 \
    --filter_groups_enable True \
    --filter_groups_metric seq_reward \
    --filter_groups_max_num_gen_batches 0 \
    algorithm.rollout_correction.rollout_is="token" \
    algorithm.rollout_correction.rollout_is_threshold=2.0 \
    algorithm.rollout_correction.rollout_is_batch_normalize="false" \
    "algorithm.rollout_correction.rollout_rs='token_k1,seq_max_k2'" \
    "algorithm.rollout_correction.rollout_rs_threshold='0.6_1.6,2.5'" \
    algorithm.rollout_correction.bypass_mode="true" \
    algorithm.rollout_correction.loss_type="ppo_clip" \
    +reward_model.max_concurrent=200